{
  "$schema": "http://json-schema.org/draft-07/schema#",
  "$id": "components/custom_analyzer.json",
  "type": "object",
  "properties": {
    "name": {
      "type": "string",
      "markdownDescription": "Name of the custom analyzer. Names must be unique within an index, and **may not** start with any of the following strings: \n- ~`lucene`~ \n- ~`builtin`~ \n- ~`mongodb`~",
      "description": "Specify a name for the custom analyzer you are defining.",
      "minLength": 1,
      "pattern": "^(?!lucene|mongodb|builtin)"
    },
    "charFilters": {
      "type": "array",
      "markdownDescription": "**Specify one or more [character filters](https://www.mongodb.com/docs/atlas/atlas-search/analyzers/character-filters/#std-label-char-filters-ref)**.\n\n Character filters examine text one character at a time and perform filtering operations.",
      "description": "Specify an array consisting of one or more character filters.",
      "items": {
        "$ref": "custom_analyzer/charFilter.json"
      },
      "minItems": 1
    },
    "tokenizer": {
      "$ref": "custom_analyzer/tokenizer.json",
      "markdownDescription": "**Specify the [tokenizer](https://www.mongodb.com/docs/atlas/atlas-search/analyzers/tokenizers/#std-label-tokenizers-ref)**.\n\n An analyzer uses a tokenizer to split chunks of text into groups, or tokens, for indexing purposes. For example, the whitespace tokenizer splits text fields into individual words based on where whitespace occurs.",
      "description": "Specify the tokenizer to use to create tokens."
    },
    "tokenFilters": {
      "type": "array",
      "markdownDescription": "**Specify one or more [token filters](https://www.mongodb.com/docs/atlas/atlas-search/analyzers/token-filters/#std-label-token-filters-ref)**.\n\n After the tokenization step, the resulting tokens can pass through one or more token filters. A token filter performs operations such as: \n- Stemming, which reduces related words, such as \"talking\", \"talked\", and \"talks\" to their root word \"talk\".\n- Redaction, the removal of sensitive information from public documents.",
      "description": "Specify an array consisting of one or more token filters.",
      "items": {
        "$ref": "custom_analyzer/tokenFilter.json"
      },
      "minItems": 1
    }
  },
  "required": ["name", "tokenizer"]
}
