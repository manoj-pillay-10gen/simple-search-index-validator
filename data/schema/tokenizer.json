{
  "$schema": "http://json-schema.org/draft-04/schema#",
  "markdownDescription": "A custom analyzer's tokenizer determines how Atlas Search splits up text into discrete chunks for indexing.",
  "type": "object",
  "oneOf": [
    { "$ref": "tokenizerEdgeGram"},
    { "$ref": "tokenizerKeyword" },
    { "$ref": "tokenizerNGram" },
    { "$ref": "tokenizerRegexCaptureGroup"},
    { "$ref": "tokenizerRegexSplit"},
    { "$ref": "tokenizerStandard"},
    { "$ref": "tokenizerUaxUrlEmail"},
    { "$ref": "tokenizerWhitespace"}
  ]
}
